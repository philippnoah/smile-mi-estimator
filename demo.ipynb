{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant helper functions.\n",
    "The utils file contains implementations of dataset-specific functions, and the estimators file implements several different estimators including:\n",
    "- InfoNCE\n",
    "- NWJ lower bound\n",
    "- NWJ eval + JS train\n",
    "- Donsker-Varadhan lower bound\n",
    "- SMILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from estimators import estimate_mutual_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the helper function for setting up the training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dimension of the Gaussian\n",
    "\n",
    "dim = 20\n",
    "\n",
    "# define the training procedure\n",
    "\n",
    "CRITICS = {\n",
    "    'separable': SeparableCritic,\n",
    "    'concat': ConcatCritic,\n",
    "}\n",
    "\n",
    "BASELINES = {\n",
    "    'constant': lambda: None,\n",
    "    # 'unnormalized': lambda: mlp(dim=dim, hidden_dim=512, output_dim=1, layers=2, activation='relu').cuda(),\n",
    "    'unnormalized': lambda: mlp(dim=dim, hidden_dim=512, output_dim=1, layers=2, activation='relu').cpu(),\n",
    "    'gaussian': lambda: log_prob_gaussian,\n",
    "}\n",
    "\n",
    "\n",
    "def train_estimator(critic_params, data_params, mi_params, opt_params, **kwargs):\n",
    "    \"\"\"Main training loop that estimates time-varying MI.\"\"\"\n",
    "    # Ground truth rho is only used by conditional critic\n",
    "    # critic = CRITICS[mi_params.get('critic', 'separable')](rho=None, **critic_params).cuda()\n",
    "    critic = CRITICS[mi_params.get('critic', 'separable')](rho=None, **critic_params).cpu()\n",
    "    baseline = BASELINES[mi_params.get('baseline', 'constant')]()\n",
    "\n",
    "    opt_crit = optim.Adam(critic.parameters(), lr=opt_params['learning_rate'])\n",
    "    if isinstance(baseline, nn.Module):\n",
    "        opt_base = optim.Adam(baseline.parameters(),\n",
    "                              lr=opt_params['learning_rate'])\n",
    "    else:\n",
    "        opt_base = None\n",
    "\n",
    "    def train_step(rho, data_params, mi_params):\n",
    "        # Annoying special case:\n",
    "        # For the true conditional, the critic depends on the true correlation rho,\n",
    "        # so we rebuild the critic at each iteration.\n",
    "        opt_crit.zero_grad()\n",
    "        if isinstance(baseline, nn.Module):\n",
    "            opt_base.zero_grad()\n",
    "\n",
    "        if mi_params['critic'] == 'conditional':\n",
    "            # critic_ = CRITICS['conditional'](rho=rho).cuda()\n",
    "            critic_ = CRITICS['conditional'](rho=rho).cpu()\n",
    "        else:\n",
    "            critic_ = critic\n",
    "\n",
    "        x, y = sample_correlated_gaussian(\n",
    "            dim=data_params['dim'], rho=rho, batch_size=data_params['batch_size'], cubic=data_params['cubic'])\n",
    "        mi = estimate_mutual_information(\n",
    "            mi_params['estimator'], x, y, critic_, baseline, mi_params.get('alpha_logit', None), **kwargs)\n",
    "        loss = -mi\n",
    "\n",
    "        loss.backward()\n",
    "        opt_crit.step()\n",
    "        if isinstance(baseline, nn.Module):\n",
    "            opt_base.step()\n",
    "\n",
    "        return mi\n",
    "\n",
    "    # Schedule of correlation over iterations\n",
    "    mis = mi_schedule(opt_params['iterations'])\n",
    "    rhos = mi_to_rho(data_params['dim'], mis)\n",
    "\n",
    "    estimates = []\n",
    "    for i in range(opt_params['iterations']):\n",
    "        mi = train_step(rhos[i], data_params, mi_params)\n",
    "        mi = mi.detach().cpu().numpy()\n",
    "        # mi = mi.cpu().numpy()\n",
    "        estimates.append(mi)\n",
    "\n",
    "    return np.array(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the dataset, critic and optimization are listed below. For `cubic` results, set `'cubic': True` in `data_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = {\n",
    "    'dim': dim,\n",
    "    'batch_size': 64,\n",
    "    'cubic': None\n",
    "}\n",
    "\n",
    "critic_params = {\n",
    "    'dim': dim,\n",
    "    'layers': 2,\n",
    "    'embed_dim': 32,\n",
    "    'hidden_dim': 256,\n",
    "    'activation': 'relu',\n",
    "}\n",
    "\n",
    "opt_params = {\n",
    "    'iterations': 100,\n",
    "    'learning_rate': 5e-4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform training over the methods. Each method should take around 2 mins to run on a single GPU under the current experiment setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for critic_type in ['separable', 'concat']:\n",
    "    mi_numpys[critic_type] = dict()\n",
    "\n",
    "    for estimator in ['infonce', 'nwj', 'js', 'smile']:\n",
    "        mi_params = dict(estimator=estimator, critic=critic_type, baseline='unnormalized')\n",
    "        mis = train_estimator(critic_params, data_params, mi_params, opt_params)\n",
    "        mi_numpys[critic_type][f'{estimator}'] = mis\n",
    "\n",
    "    estimator = 'smile'\n",
    "    for i, clip in enumerate([1.0, 5.0]):\n",
    "        mi_params = dict(estimator=estimator, critic=critic_type, baseline='unnormalized')\n",
    "        mis = train_estimator(critic_params, data_params, mi_params, opt_params, clip=clip)\n",
    "        mi_numpys[critic_type][f'{estimator}_{clip}'] = mis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting helper functions.\n",
    "\n",
    "def find_name(name):\n",
    "    if 'smile_' in name:\n",
    "        clip = name.split('_')[-1]\n",
    "        return f'SMILE ($\\\\tau = {clip}$)'\n",
    "    else:\n",
    "        return {\n",
    "            'infonce': 'CPC',\n",
    "            'js': 'JS',\n",
    "            'nwj': 'NWJ',\n",
    "            'flow': 'GM (Flow)',\n",
    "            'smile': 'SMILE ($\\\\tau = \\\\infty$)'\n",
    "        }[name]\n",
    "\n",
    "def find_legend(label):\n",
    "    return {'concat': 'Joint critic', 'separable': 'Separable critic'}[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb#ch0000011?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(find_name(key), fontsize\u001b[39m=\u001b[39m\u001b[39m18\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb#ch0000011?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m net \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mseparable\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb#ch0000011?line=15'>16</a>\u001b[0m     mis \u001b[39m=\u001b[39m mi_numpys[net][key]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb#ch0000011?line=16'>17</a>\u001b[0m     p1 \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mplot(mis, alpha\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/philippeibl/Documents/administrative/professional/research/ils/information_theory/dev/smile-mi-estimator/demo.ipynb#ch0000011?line=17'>18</a>\u001b[0m     mis_smooth \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(mis)\u001b[39m.\u001b[39mewm(span\u001b[39m=\u001b[39mEMA_SPAN)\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'concat'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot 5 of the results, InfoNCE, NWJ, Smile 1.0, 5.0, infty\n",
    "\n",
    "ncols = 5\n",
    "nrows = 1\n",
    "EMA_SPAN = 200\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(4 * ncols, 4 * nrows))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "mi_true = mi_schedule(opt_params['iterations'])\n",
    "        \n",
    "for i, estimator in enumerate(['infonce', 'nwj']):\n",
    "    key = f'{estimator}'\n",
    "    plt.sca(axs[i])\n",
    "    plt.title(find_name(key), fontsize=18)\n",
    "    for net in ['concat', 'separable']:\n",
    "        mis = mi_numpys[net][key]\n",
    "        p1 = plt.plot(mis, alpha=0.3)[0]\n",
    "        mis_smooth = pd.Series(mis).ewm(span=EMA_SPAN).mean()\n",
    "        plt.plot(mis_smooth, c=p1.get_color(), label=find_legend(net))\n",
    "    plt.ylim(0, 11)\n",
    "    plt.xlim(0, 20000)\n",
    "    plt.plot(mi_true, color='k', label='True MI')\n",
    "    if i == 0:\n",
    "        plt.ylabel('MI (nats)')\n",
    "        plt.xlabel('Steps')\n",
    "        plt.axhline(np.log(64), color='k', ls='--', label='log(bs)')\n",
    "        plt.legend()\n",
    "\n",
    "estimator = 'smile'\n",
    "for i, clip in enumerate([1.0, 5.0, None]):\n",
    "    if clip is None:\n",
    "        key = estimator\n",
    "    else:\n",
    "        key = f'{estimator}_{clip}'\n",
    "\n",
    "    plt.sca(axs[i+2])\n",
    "    plt.title(find_name(key), fontsize=18)\n",
    "    for net in ['concat', 'separable']:\n",
    "        mis = mi_numpys[net][key]\n",
    "        EMA_SPAN = 200\n",
    "        p1 = plt.plot(mis, alpha=0.3)[0]\n",
    "        mis_smooth = pd.Series(mis).ewm(span=EMA_SPAN).mean()\n",
    "        plt.plot(mis_smooth, c=p1.get_color(), label=find_legend(net))\n",
    "    plt.plot(mi_true, color='k', label='True MI')\n",
    "    plt.ylim(0, 11)\n",
    "    plt.xlim(0, 20000)\n",
    "\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, the SMILE estimators have much better performance compared to the alternative methods with clipping.\n",
    "We note that SMILE (infty) is simply a version of DV + JS, where we obtain density ratios from JS and use DV to directly estimate the mutual information. This has much higher variance, and is biased lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
